---
title: "01-read_filter_normalize_scRNAseq_ALCL"
author: "Putri Ramadani"
date: "2025-05-28"
output: html_document
---

This is documentation for the script `scRNAseq_ALCL_Thymus_RLN_Adult_Ped-merged.Rmd`, which is part of the analysis pipeline for single-cell RNA sequencing data from ALCL patients. 
The script performs data import, filtering, and normalization.
Sample patients:
ALCL001
ALCL002
ALCL003
ALCL004
ALCL005
ALCL006
ALCL007
ALCL008
UHNALCL01
UHNALCL02
UHNALCL03
UHNALCL04

Control samples:
CLC02916 -> Reactive Lymph Node
CLC02917
CLC03483
CLC03510 (removed due to low cell numbers)
CLC04353
EX01176 -> Thymus 
EX01177 (missing in the cluster)
EX01178
EX01179
EX01180

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ============================ 
# Load Libraries & Set Up
# ============================ 
```{r}
# Load necessary libraries
library(Seurat)
library(pheatmap)
library(ggrepel)
library(ggplot2)
library(dplyr)
library(tidyr)
library(readxl)

# Set random seed for reproducibility
set.seed(12345)
setwd('~/scRNAseq_ALCL_Thymus_RLN')
lib.info <- read_xlsx('metadata/lib_ALCL_Thymus_RLN.xlsx')

# Create directories for data and figures if they don't exist
dir.create("data", recursive = TRUE, showWarnings = FALSE)
dir.create("figures", recursive = TRUE, showWarnings = FALSE)
```


# ============================
# Create Seurat Object
# ============================
```{r}
sc.obj <- NULL
for (i in 1:nrow(lib.info)) {
  i.df <- lib.info[i,]
  i.dir <- i.df$AnalysisDir
  i.data <- Read10X(data.dir = i.dir)
  i.obj <- CreateSeuratObject(counts = i.data, project = i.df$Sample)
  i.obj <- RenameCells(i.obj, add.cell.id = i.df$Sample)
  sc.obj <- if (is.null(sc.obj)) i.obj else merge(sc.obj, i.obj)
}
```

# ============================
# Add Metadata (Full)
# ============================
```{r}
# Add metadata from the library information
lib.info <- read_xlsx('metadata/lib_ALCL_Thymus_RLN.xlsx')  # keep full metadata
sc.obj$Sample <- sc.obj$orig.ident
meta <- sc.obj@meta.data
meta$CellBarcode <- rownames(meta)
meta_merged <- left_join(meta, lib.info, by = "Sample")
rownames(meta_merged) <- meta_merged$CellBarcode
meta_merged$CellBarcode <- NULL
sc.obj@meta.data <- meta_merged
```

# ============================
# QC Filtering (mt% + MAD)
# ============================
```{r}
# Add metadata for QC
sc.obj[["percent.mt"]] <- PercentageFeatureSet(sc.obj, pattern = "^MT-")
sc.obj[["percent.rb"]] <- PercentageFeatureSet(sc.obj, pattern = "^RP[LS]")

# Gene count outliers using MAD
keep.nGene <- rep(NA, ncol(sc.obj))
for (s in unique(sc.obj$orig.ident)) {
  s.idx <- which(sc.obj$orig.ident == s)
  s.median <- median(sc.obj$nFeature_RNA[s.idx])
  s.mad <- mad(sc.obj$nFeature_RNA[s.idx])
  keep.nGene[s.idx] <- (sc.obj$nFeature_RNA[s.idx] >= s.median - 4*s.mad) &
                       (sc.obj$nFeature_RNA[s.idx] <= s.median + 4*s.mad)
}
sc.obj$keep_nGene <- keep.nGene

# Final filter: percent.mt < 20 and pass MAD filter
sc.obj <- subset(sc.obj, subset = percent.mt < 20 & keep_nGene)

# Remove samples with <1000 cells
cell_counts <- table(sc.obj$orig.ident)
samples_to_keep <- names(cell_counts[cell_counts >= 1000])
sc.obj <- subset(sc.obj, orig.ident %in% samples_to_keep)

# Save filtered object
saveRDS(sc.obj, "data/250625_merged_scobj_qc_filtered_applied.rds")

# Save cell counts after filtering
write.csv(as.data.frame(table(sc.obj$orig.ident)), "data/cell_counts_after_QC_applied.csv")

```

# ============================
# Normalize, Variable Features, PCA, UMAP, Clustering
# ============================
```{r}
sc.obj <- NormalizeData(sc.obj)
sc.obj <- FindVariableFeatures(sc.obj, selection.method = "vst", nfeatures = 2000)
top10 <- head(VariableFeatures(sc.obj), 10)

# Plot top 10 variable genes
png("figures/250625_top10_variable_genes.png", width = 800, height = 600)
plot <- VariableFeaturePlot(sc.obj)
plot <- LabelPoints(plot, points = top10, repel = TRUE, size = 5) +
  theme(axis.text = element_text(size = 20),
        axis.title = element_text(size = 24),
        legend.title = element_text(size = 24),
        legend.text = element_text(size = 20)) +
  ggtitle('Top 10 Variable Genes')
print(plot)
dev.off()

# Save ranked variable genes
hvf.info <- HVFInfo(sc.obj)
hvf.info$gene <- rownames(hvf.info)
hvf.ranked <- hvf.info[order(-hvf.info$variance.standardized), ]
write.csv(hvf.ranked, "data/all_variable_features_ranked.csv", row.names = FALSE)

# Scale, PCA, UMAP, Clustering
sc.obj <- ScaleData(sc.obj, verbose = FALSE)
sc.obj <- RunPCA(sc.obj, npcs = 30, verbose = FALSE)
sc.obj <- RunUMAP(sc.obj, reduction = "pca", dims = 1:30, reduction.name = 'umap_GEX')
sc.obj <- FindNeighbors(sc.obj, reduction = "pca", dims = 1:30)
sc.obj <- FindClusters(sc.obj, resolution = 0.8)
```

# ============================
# UMAP Plots (Clusters, Metadata)
# ============================
```{r}
# Plot UMAP with clusters
png("figures/250626_umap_Seurat_clusters_before_correction.png", width = 800, height = 600)
DimPlot(sc.obj, group.by = 'seurat_clusters', reduction = 'umap_GEX', label = TRUE, label.size = 10, raster=FALSE)
dev.off()

png("figures/250626_umap_StudyID_before_correction.png", width = 1200, height = 900)
DimPlot(sc.obj, group.by = 'StudyID', reduction = 'umap_GEX', label = FALSE, label.size = 10, raster=FALSE) +
  theme(legend.text = element_text(size = 30),
        axis.title = element_text(size = 30),
        axis.text = element_text(size = 30))
dev.off()

png("figures/250626_umap_Category1_before_correction.png", width = 1200, height = 900)
DimPlot(sc.obj, group.by = 'Category1', reduction = 'umap_GEX', label = TRUE, label.size = 10, raster=FALSE) +
  theme(legend.text = element_text(size = 30),
        axis.title = element_text(size = 30),
        axis.text = element_text(size = 30))
dev.off()

png("figures/250626_umap_Category2_before_correction.png", width = 1200, height = 900)
DimPlot(sc.obj, group.by = 'Category2', reduction = 'umap_GEX', label = FALSE, label.size = 10, raster=FALSE) +
  theme(legend.text = element_text(size = 30),
        axis.title = element_text(size = 30),
        axis.text = element_text(size = 30))
dev.off()
```

# ============================
# Save Final Clustered Seurat Object
# ============================
```{r}
# Create directory for Seurat objects and save the clustered object
dir.create("data/Seurat_objects", recursive = TRUE, showWarnings = FALSE)
save(sc.obj, file = "data/Seurat_objects/sc.obj_clustered.Rdata")
```


# TO-DO: 
## Do normalization with SoupX
## Do Batch Correction, compare with previous clustering, and save the corrected Seurat object
## Manual cell type annotation